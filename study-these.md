Some additional resources to study:

1. Use of metric to improve fraud detection.

> This is an example where the dataset is imbalanced with fewer instances of positive class because of a fewer number of actual fraud records in the dataset. In such scenarios where we care more about the positive class, then using PR AUC is a better choice, which is more sensitive to the improvements for the positive class.

> PR AUC is a curve that combines precision (PPV) and Recall (TPR) in a single visualization. For every threshold, you calculate PPV and TPR and plot it. The higher on y-axis your curve is the better your model performance.

> Please review these excellent resources for a deep-dive into PR AUC.

> https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc

> https://machinelearningmastery.com/imbalanced-classification-with-the-fraudulent-credit-card-transactions-dataset/

2. Viz for detecting outliers

> https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba

> https://humansofdata.atlan.com/2017/10/how-to-find-outliers-data-set/

3. Specificity

https://www.statisticshowto.datasciencecentral.com/sensitivity-vs-specificity-statistics/

4. SageMaker high level python library

https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html

5. SageMaker IAM

https://docs.aws.amazon.com/sagemaker/latest/dg/security_iam_service-with-iam.html

6. TF-IDF

https://en.wikipedia.org/wiki/Tf%E2%80%93idf

7. Inference pipelines

https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html



