# Text-Based Features

For text analysis, need to transform clean up the text values, then convert to numerical values (needed by the models)

Bag-of-words Model

* Does not keep track of the sequence of workds
* Represents documents as vector of numbers, once for each work (tokenize, count, and normalize)

Note:

* Sparse matrix implementation is typically used, ignores relative position of workds
* Can be extended to bag of n-grams of works or of characters

Term frequency vectors

Count Vectorizer

* Per word value is count (also called term frequency)
    * Note: also includes lowercasing and tokenization on white space and puncutation.
    * scikit-learn: sklearn.feature_extraction.text.CountVectorizer

TfidfVectorizer

* Term frequency tunes inverse document-frequency
* Per-word value is downweighted for terms common across documents (for example "the")
* scikit-learn: sklearn.feature_extraction.text.TfidfVectorizer

Hashing Vectorizer

* More efficient mapper from text to term index
* Stateless mapper from text to term index
* sklearn.feature_extraction.text.HashingVectorizer