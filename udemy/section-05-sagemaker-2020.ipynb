{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to SageMaker\n",
    "\n",
    "Fully managed cloud based machine learning service, made up of 3 capabilities\n",
    "\n",
    "* Build - Jupyter Notebook development environment\n",
    "    * Extensive collection of popular machine learning algorithms\n",
    "    * Preconfigured to run TensorFlow and Apache MxNet\n",
    "    * Bring your own algorithm\n",
    "* Train - managed training infrastructure\n",
    "    * Distribute training across one or more instances\n",
    "    * Managed model training infrastructure\n",
    "    * Scales to petabytes\n",
    "    * Compute instances automatically launched and release, artifacts stored in S2\n",
    "* Deploy - scalable hosting infrastructure\n",
    "    * Real time prediction\n",
    "        * For interactive and low latency used cases\n",
    "        * Autoscaling to maintain adequate capacity, replace unhealthy instances, scale-out and scale-in based on workload\n",
    "    * Batch transform\n",
    "        * Non-interactive use-cases\n",
    "        * Suitabke where you need inference for your entire dataset, don't need a persistent real-time endpoint, don't need sub-second latency performance\n",
    "        * Manages all resources needed for batch transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance Types and Pricing\n",
    "\n",
    "Instance families\n",
    "\n",
    "* Standard\n",
    "    * balanced CPU, memory, and network\n",
    "    * T2, T3, M5 - T for bursty, M can handle sustained load\n",
    "* Compute optimized\n",
    "    * Highest CPU perf\n",
    "    * Latest CPUs - C4, C5\n",
    "    * Good for both training and hosting\n",
    "* Accelerated computing\n",
    "    * graphics/GPU compute\n",
    "    * Speed up algs optimized for GPUs\n",
    "    * P2, P3\n",
    "    * Costs more, but can reduce training time, can also serve GPU optimized inferencce\n",
    "* Inference acceleration\n",
    "    * Add-on Fractional GPUs\n",
    "    * Some algorithms are GPU intensive during training but need only fractional GPU during inference\n",
    "    \n",
    "    \n",
    "How to decide?\n",
    "\n",
    "* CPU vs GPU\n",
    "* Try difference sizes when family selected\n",
    "* Instance type and size\n",
    "    * <instance type><hardware gen>.<size> e.g. c5.2xlarge\n",
    "    \n",
    "Pricing components\n",
    "\n",
    "* Instance type and size\n",
    "* Fractional GPUs\n",
    "* Storage\n",
    "* Data transfer\n",
    "* Region\n",
    "\n",
    "Training - On Demand Pricing\n",
    "\n",
    "* Instance hourly cost\n",
    "* Storage\n",
    "* Instances are automatically launched and terminated\n",
    "\n",
    "Hosting - Realtime\n",
    "\n",
    "* Instance + Fractional GPU \n",
    "* Storage\n",
    "* Data transfer\n",
    "\n",
    "Hosting - Batch\n",
    "\n",
    "* Instance + Fractional GPU \n",
    "* Storage\n",
    "* Data transfer\n",
    "* Automatic termination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Supported Data Formats\n",
    "\n",
    "Training\n",
    "\n",
    "* CSV\n",
    "* Record IO\n",
    "* Algorithm specific formats (LibSVM, JSON, Parquet)\n",
    "\n",
    "Training data needs to be stored in S3, single file or split across files in a folder.\n",
    "\n",
    "Two ways to transfer data from s3 to training instance.\n",
    "\n",
    "* File mode: copies entire dataset from s3 to training instance, space needs are entire data set size plus final model artifacts\n",
    "* Pipe mode: streams data from s3 to training instance. Faster start time and better throughput, space needs are for final model artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build-In Algorithms\n",
    "\n",
    "SageMaker Training and Hosting Options\n",
    "\n",
    "* Use built in algorithms\n",
    "* Use pre built container images with popular frameworks like MxNet, TensorFlow,  scikit-leann, PyTorch\n",
    "* Extend prebuilt containers\n",
    "* Use customer container images - custom algorithm, language, frameworks\n",
    "\n",
    "Built In Algorithms\n",
    "\n",
    "* Provided by SageMaker\n",
    "* Easy to scale and use\n",
    "* Optimized for the AWS cloud\n",
    "* GPU support\n",
    "\n",
    "Blazing Text\n",
    "\n",
    "* Used for text\n",
    "* Cloud optimized version of fasttext\n",
    "* Unsupervised version: Convert word to vector (Word2Vec)\n",
    "    * Text preprocessing step for downstream NLP, sentiment analysis, named entity recognition and translatopn\n",
    "    * Words semantically similar have vectors that are closer to each other, for example vegatable name locations in vector space\n",
    "* Supervised: multi-class, multi-label clasification\n",
    "    * Classification based on text (single label), for example spam detection (spam/notspam)\n",
    "    * Single instance can belong to many classes (multi-label), for example a movice can belong to multiple generes\n",
    "* See SageMaker blazing text and [here](https://fasttext.cc)\n",
    "\n",
    "Object2Vec\n",
    "\n",
    "* Supervised\n",
    "* Can be used for classicication, regression\n",
    "* Extends Word2Vec: learns relationship between pairs of objects, captures structure of sentences\n",
    "* Examples: similartity based on customer-product, movie-ratings, etc.\n",
    "\n",
    "Factorization Machines\n",
    "\n",
    "* Supervised\n",
    "* Used for regression, classification\n",
    "* Works very well with high diminsional sparse datasets\n",
    "* Popular for building recommender systems\n",
    "* Collaborative filtering\n",
    "* Example: movie recommendations based on your viewing habits, cross recommend based on similar users\n",
    "\n",
    "K-Nearest Neighbors\n",
    "\n",
    "* Supervise, used for regression and clasifcation\n",
    "* Classification - queries K-nearest neighbors and assigns majority class for the instance\n",
    "* Regression - queries k-nearest neighbors and returns average value for the instance\n",
    "* Does not scale well for large datasets\n",
    "\n",
    "Linear Learner\n",
    "\n",
    "* Supervised\n",
    "* Regression, classification\n",
    "* Linear models used for regression, binary classification, and multi-class classification\n",
    "\n",
    "XGBoost\n",
    "\n",
    "* Supervised\n",
    "* Regression, classification\n",
    "* Gradient boosted trees algorithm, very popular, won serveral competitions\n",
    "\n",
    "DeepAR\n",
    "\n",
    "* Supervised, used for timeseries forecasting\n",
    "* Train multiple related time series using a single model\n",
    "* Generate predictions for new, similar timeseries\n",
    "\n",
    "Object Detection\n",
    "\n",
    "* Supervised, classification\n",
    "* Used for image analysis, detects and classifies objects in an image, returns bounding box of each object location\n",
    "\n",
    "Image Classification\n",
    "\n",
    "* Supervised, classification\n",
    "* Image analysis algorithm, classifies entire image, supports multilabels\n",
    "\n",
    "Semantic Segmentation\n",
    "\n",
    "* Supervised, classificsation\n",
    "* Image analysis algorithm for computer vision applications\n",
    "* Tags each pixel in an image with a class label\n",
    "* Example: identify shape of car\n",
    "\n",
    "Sequence to Sequence (seq2seq)\n",
    "\n",
    "* Supervised, convert a sequence of tokens\n",
    "* Input: sequence of tokens\n",
    "* Output: another sequence of tokens\n",
    "* Examples: text summarization, language translation, speech to text\n",
    "\n",
    "K-Means\n",
    "\n",
    "* Unsupervised, clustering\n",
    "* Identifying discrete groups within data\n",
    "* Members of a group are as similar as possible to one another and as different as possible from members of other groups\n",
    "\n",
    "Latent Dirichlet Allocation (LDA)\n",
    "\n",
    "* Unsupervised, topic modeling\n",
    "* Group documents by user specified \"number\" of topics\n",
    "* For documents, assigns a probability scope for each topic\n",
    "\n",
    "Neural Topic Modeling\n",
    "\n",
    "* Unsupervised, topic modeling\n",
    "* Similar to LDA\n",
    "\n",
    "Principal Component Analysis (PCA)\n",
    "\n",
    "* Unsupervised, Diminionality Reduction\n",
    "* Reduces dimensionality of dataset while retaining as much information as possible\n",
    "* Returns components - new sets of features that are composites of original features and that are uncorrelated to on another\n",
    "* Examples: reduce the dimensions of a dataset, visualize high dimensional datasets, remove highly correlated features\n",
    "\n",
    "Random Cut Forest (RCF)\n",
    "\n",
    "* Unsupervised, anomaly detection\n",
    "* Anomalous points are observations that diverge from otherwise well-structured or patterned data\n",
    "* For each data point, RCF assigns an anomaly score\n",
    "* Low score indicates normal data and high score indicates an anomaly.\n",
    "\n",
    "IP Insights\n",
    "\n",
    "* Unsupervised, detect unusual network activity\n",
    "* Learns from (entity, IPv4 address) pairs\n",
    "* Entity can be account id, user id\n",
    "* For a given pair returns a score\n",
    "* High score indicates unusual event - website can trigger an MFA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Ground Truth\n",
    "\n",
    "Automatic labeling\n",
    "\n",
    "* Learns based on examples\n",
    "* Very cost effective\n",
    "\n",
    "Manual Labeling\n",
    "\n",
    "* Human Labelling - Mechanical Turk\n",
    "* Manages workflow\n",
    "\n",
    "## SageMaker Neo\n",
    "\n",
    "* Run machine learning algorithms anywhere in the cloud and at edge location\n",
    "* Edge - where latency is critical\n",
    "* Cross compilation capability that can optimize your algorithms to run on Intel, nvidia, arm, and other hardware\n",
    "\n",
    "## Bring Your Own Algorithms\n",
    "\n",
    "* SageMaker makes extensive use of Docker containers for build and runtime tasks\n",
    "* [Bring your own algorithm](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms.html) is also based on containers\n",
    "* Popular pattern - Apache Spark for preprocesing, train and host with SageMaker\n",
    "\n",
    "Popular Framework Support\n",
    "\n",
    "* TensorFlow\n",
    "* MxNet\n",
    "* scikit-learn\n",
    "* PyTorch\n",
    "* Chainer\n",
    "* SparkML\n",
    "\n",
    "SageMaker provides SDKs and prebuilt docker images to train and host models using these frameworks\n",
    "\n",
    "Can develop your own algorithms with frameworks and languages of your choice by conforming with SageMaker container interfaces.\n",
    "\n",
    "Deep Leaning AMIs\n",
    "\n",
    "* Launch EC2 instances preconfigured with all the tools and frameworks \n",
    "* Use cases include modifying DK frameworks or extending them, troubleshooting frameworks, contributing to framework projects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
