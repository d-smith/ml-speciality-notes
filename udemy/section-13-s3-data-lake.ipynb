{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Lakes in AWS\n",
    "\n",
    "## Overview\n",
    "\n",
    "Typical ML project - spends 70% of the effort on data prep and cleaning. A data lake can help streamline the data related parts of an ML project.\n",
    "\n",
    "Data Lake vs Data Warehouse\n",
    "\n",
    "* A data lake is a vast pool of raw data, the purpose for which is not yet defined. A data warehouse is a repository for structured, filtered data that has already been processes for a specific purpose.\n",
    "\n",
    "AWS whitepaper - [Data Lake on AWS](https://docs.aws.amazon.com/whitepapers/latest/building-data-lakes/building-data-lake-aws.html)\n",
    "\n",
    "Aspects of data lakes\n",
    "\n",
    "* Storage \n",
    "* Governance\n",
    "* Analytics\n",
    "\n",
    "AWS data lake related services\n",
    "\n",
    "* Storage\n",
    "    * S3 - storage\n",
    "    * Glacier - backup and archival\n",
    "    \n",
    "* Ingestion\n",
    "    * Kinesis Firehose\n",
    "    * Storage Gateway - for on premise data to cloud. Three modes - file share, block storage, or virtual tape device.\n",
    "    * Large data migration - Snowball appliance (petabyte scale transfers) and Snowmobile (exabyte scale).\n",
    "    * SDK, CLI and more to store data in S3\n",
    "    \n",
    "* Data Catalog\n",
    "    * Without a metadata catalog to aid in discover of data in the data lake you end up with a data swamp.\n",
    "    * A data swamp is a deteriorated and unmanaged data lake that is either inaccessible to its intended users or is providing little value.\n",
    "    * DIY - make data discoverable and usable. Build your own using s3, lambda, elastic search, dynamodb to maintain metadata.\n",
    "    * Glue - data catalog (metadata repository). Automatically crawl and collect metadata from s3, ddb, and any database that supports jdbc connectivity,\n",
    "    \n",
    "## Kinesis\n",
    "\n",
    "Allows you to ingest, buffer, and process streaming data in real-time.\n",
    "\n",
    "Streaming data\n",
    "\n",
    "* Generated continuously from thousands of sources. \n",
    "* Small payloads\n",
    "\n",
    "Batch processing - data ingested and stored, processed in batches at various points in time (hourly, daily, etc).\n",
    "Stream processing - analyze data as it arrives, response in seconds.\n",
    "\n",
    "Kinesis Capabilities\n",
    "\n",
    "* Video streams - use for video playback, monitoring, rekognition, etc\n",
    "* Data streams - data streaming, use kinesis data analytics, spark on EMR, EC2, lambda\n",
    "* Firehose - collect data and directly load in the s3, redshift, elasticsearch, and splunk.\n",
    "* Kinesis Data Analytics - process using SQL or Flink\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
