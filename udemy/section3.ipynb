{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes from Section 3 Machine Learning Concepts\n",
    "\n",
    "Three types of machine learning:\n",
    "\n",
    "* Supervised\n",
    "* Unsupervised\n",
    "* Reinforcement Learning\n",
    "\n",
    "## Supervised Learning\n",
    "\n",
    "Train a model with labeled data, predict the output for a new input.\n",
    "\n",
    "Different models can yield different predictions - how to you evaluate different models?\n",
    "\n",
    "Training data often arranged in tables.\n",
    "\n",
    "* Rows: Example, sample, instance, or observation\n",
    "* Columns: Feature or attribute\n",
    "* Labeled output column: label or target\n",
    "\n",
    "Labeled data typically split into two parts: training set and test set.\n",
    "\n",
    "* Build model with the training set\n",
    "* Test the model using the test set\n",
    "\n",
    "Test results can be used in evaluating data quality.\n",
    "\n",
    "You need to be careful in how you split the labeled data into training and test sets. Often techniques like shuffling are applied.\n",
    "\n",
    "### Regression Models\n",
    "\n",
    "Use to predict a numeric output, e.g. home prices.\n",
    "\n",
    "### Binary Classification\n",
    "\n",
    "Predict a binary output, e.g. yes, no. Email spam, does the social media post need a response.\n",
    "\n",
    "### Multi-Class Classification\n",
    "\n",
    "Used for predicting one out of several outcomes, e.g. How is the weather tomorrow (sunny, rainly, windy, snowy, etc)\n",
    "\n",
    "## Unsupervised Learning\n",
    "\n",
    "There is no defined target, only data. Used to group similar observerations.\n",
    "\n",
    "Example uses: anomaly detection, words using in similar context, group similar documents, customer segmentation.\n",
    "\n",
    "Unsupervised Learning Algorithms\n",
    "\n",
    "* Clustering\n",
    "* Dimensionality Reduction (reduce number of features for a model)\n",
    "    * Principle Component Algorithm\n",
    "* Groups words that are used in similar context or have similar meansings\n",
    "\n",
    "## Reinforcement Learning\n",
    "\n",
    "Used in circumstances where decisions must be made under uncertainty. Examples: autonomous driving, games.\n",
    "\n",
    "Reinforcement learning usesreward functions to reward correct decisions and punish incorrect decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data In Real Life\n",
    "\n",
    "Often dealing with a mix of data\n",
    "\n",
    "* Numeric\n",
    "* Text\n",
    "* Categorical\n",
    "\n",
    "### Handling Categorical Data\n",
    "\n",
    "Used to describe qualitative properties of observations\n",
    "\n",
    "Day of Week - Sunday, Monday, etc. - text based categoricals like day of week can be *converted to numeric*, e.g. Sunday is 1, Monday is 2, etc.\n",
    "\n",
    "Several machine learning libraries do not handle even numeric categorical observations, as well as algorithms like linear regression. In this case the data is encoded using *one hot encoding* - one column per categorical value, use 1 for category value that applies, 0 for those that do not.\n",
    "\n",
    "What if you want to model or capture the interplay between two categorical values, for example day of week (Sunday, Monday, ...) and weather (Sunny, Cloudy, Snow, ...)? Interaction between features can be handled by combining features (aka Catersian Transformation) - for example Sunday_Sunny, Sunday_Cloudy, ,,,\n",
    "\n",
    "### Text Data\n",
    "\n",
    "Requires special handling. Example transformations:\n",
    "\n",
    "* NGRAM transformation\n",
    "* Orthogonal Sparse Bigram (OSB) transformation\n",
    "* Lowercase transformation - improve the signal by normalizing case\n",
    "* Remove punctuation transformation\n",
    "* Cartesian transformation\n",
    "\n",
    "Text to numeric transformation - bag of words: word is feature, value is count\n",
    "\n",
    "Splitting on whitespace can lose meaning: \"this is not working. disappointed\" vs \"this is working. not disappointed\". Here parsing on whitespace yields the same encoding and loses the underlying meaning.\n",
    "\n",
    "NGRAM transformation - provide a window for capturing word combinations. Now we can discriminate the above two. \n",
    "\n",
    "[OSB](https://docs.aws.amazon.com/machine-learning/latest/dg/data-transformations-reference.html#orthogonal-sparse-bigram-osb-transformation) is an on this idea.\n",
    "\n",
    "Stemming - words are reduced to root word, root word used for training. For example working, worked, works all reduce to work.\n",
    "\n",
    "### Numeric Data\n",
    "\n",
    "* Numeric value as-is or using normalization transformation for linear relationships.\n",
    "* Binning transformation - convert to categorical for non-linear realtionship\n",
    "\n",
    "Example - features can be of different scales, such as GDP in trillions and population in millions. To avoid large values dominating, you can normalize the features, for example scale GDP to units of trillions, population to units of millions.\n",
    "\n",
    "Binning - convert ranges of values to categories, useful when you suspect non-linearities. Allows the model to assign different weights to bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
